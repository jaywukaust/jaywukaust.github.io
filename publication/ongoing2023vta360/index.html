<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=google-site-verification content="7MghMiEezWCdLZfbrgYR845yxCJj-g02bSAnoythP1A"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.5.0"><meta name=author content="Dai-Jie Wu"><meta name=description content="Existing video-to-avatar systems predominantly focus on reconstructing head avatars within the field of view of the input videos, which impedes the generation of complete, all-rounded 3D avatars that can render from any novel views. We introduce an innovative framework, video-to-avatar360, to reconstruct a full 360-degree implicit neural head avatar from a single monocular frontal video. We first propose to use the signed distance function extracted from the prior mesh as a condition to the canonical Neural Radiance Field, to provide a coarse clue for the geometry of the full head avatar. We then incorporate a personalized diffusion guidance, DreamBooth-SDS, to optimize the NeRF in the novel views while being identity-preserving. Video-to-Avatar360 enables the generation of photorealistic 360-degree avatars, achieving a substantial performance leap over the state-of-the-art, for both reference-view reconstruction and novel view synthesis."><link rel=alternate hreflang=en-us href=https://jaywukaust.github.io/publication/ongoing2023vta360/><meta name=theme-color content="#2962ff"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/academic.min.7ff2359a5a6c81fb86a941f3d6a32bce.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-100690611-1"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","UA-100690611-1",{}),document.addEventListener("click",onClickCallback,!1)</script><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/img/icon.ico><link rel=apple-touch-icon type=image/png href=/img/icon.ico><link rel=canonical href=https://jaywukaust.github.io/publication/ongoing2023vta360/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Dai-Jie Wu"><meta property="og:url" content="https://jaywukaust.github.io/publication/ongoing2023vta360/"><meta property="og:title" content="VTA360: 360° Head Avatar Generation from Monocular Frontal Videos | Dai-Jie Wu"><meta property="og:description" content="Existing video-to-avatar systems predominantly focus on reconstructing head avatars within the field of view of the input videos, which impedes the generation of complete, all-rounded 3D avatars that can render from any novel views. We introduce an innovative framework, video-to-avatar360, to reconstruct a full 360-degree implicit neural head avatar from a single monocular frontal video. We first propose to use the signed distance function extracted from the prior mesh as a condition to the canonical Neural Radiance Field, to provide a coarse clue for the geometry of the full head avatar. We then incorporate a personalized diffusion guidance, DreamBooth-SDS, to optimize the NeRF in the novel views while being identity-preserving. Video-to-Avatar360 enables the generation of photorealistic 360-degree avatars, achieving a substantial performance leap over the state-of-the-art, for both reference-view reconstruction and novel view synthesis."><meta property="og:image" content="https://jaywukaust.github.io/img/avatar.jpg"><meta property="twitter:image" content="https://jaywukaust.github.io/img/avatar.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2023-12-24T00:00:00+00:00"><meta property="article:modified_time" content="2023-12-24T14:36:06+08:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://jaywukaust.github.io/publication/ongoing2023vta360/"},"headline":"VTA360: 360° Head Avatar Generation from Monocular Frontal Videos","datePublished":"2023-12-24T00:00:00Z","dateModified":"2023-12-24T14:36:06+08:00","author":{"@type":"Person","name":"__**Dai-Jie Wu**__"},"publisher":{"@type":"Organization","name":"Dai-Jie Wu","logo":{"@type":"ImageObject","url":"https://jaywukaust.github.io/img/icon.ico"}},"description":"Existing video-to-avatar systems predominantly focus on reconstructing head avatars within the field of view of the input videos, which impedes the generation of complete, all-rounded 3D avatars that can render from any novel views. We introduce an innovative framework, video-to-avatar360, to reconstruct a full 360-degree implicit neural head avatar from a single monocular frontal video. We first propose to use the signed distance function extracted from the prior mesh as a condition to the canonical Neural Radiance Field, to provide a coarse clue for the geometry of the full head avatar. We then incorporate a personalized diffusion guidance, DreamBooth-SDS, to optimize the NeRF in the novel views while being identity-preserving. Video-to-Avatar360 enables the generation of photorealistic 360-degree avatars, achieving a substantial performance leap over the state-of-the-art, for both reference-view reconstruction and novel view synthesis."}</script><title>VTA360: 360° Head Avatar Generation from Monocular Frontal Videos | Dai-Jie Wu</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id=navbar-main><div class=container><a class=navbar-brand href=/>Dai-Jie Wu</a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#accomplishments><span>Accomplishments</span></a></li></ul><ul class="navbar-nav ml-auto"><li class=nav-item><a class="nav-link js-search" href=#><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></div></nav><div class=pub><div class="article-container pt-3"><h1>VTA360: 360° Head Avatar Generation from Monocular Frontal Videos</h1><div class=article-metadata><div><span><strong><strong>Dai-Jie Wu</strong></strong></span>, <span>Guocheng Qian</span>, <span>Tingting Liao</span>, <span>Qian Wang</span>, <span>Silvio Giancola</span>, <span>Peter Wonka</span>, <span>Sergey Tulyakov</span>, <span>Kfir Aberman</span>, <span>Hao Li</span>, <span>Bernard Ghanem</span></div><span class=article-date>December 2023</span><div class=share-box aria-hidden=true><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://jaywukaust.github.io/publication/ongoing2023vta360/&text=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos" target=_blank rel=noopener class=share-btn-twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https://jaywukaust.github.io/publication/ongoing2023vta360/&t=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos" target=_blank rel=noopener class=share-btn-facebook><i class="fab fa-facebook-f"></i></a></li><li><a href="mailto:?subject=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos&body=https://jaywukaust.github.io/publication/ongoing2023vta360/" target=_blank rel=noopener class=share-btn-email><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://jaywukaust.github.io/publication/ongoing2023vta360/&title=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos" target=_blank rel=noopener class=share-btn-linkedin><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://web.whatsapp.com/send?text=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos%20https://jaywukaust.github.io/publication/ongoing2023vta360/" target=_blank rel=noopener class=share-btn-whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https://jaywukaust.github.io/publication/ongoing2023vta360/&title=VTA360:%20360%c2%b0%20Head%20Avatar%20Generation%20from%20Monocular%20Frontal%20Videos" target=_blank rel=noopener class=share-btn-weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Existing video-to-avatar systems predominantly focus on reconstructing head avatars within the field of view of the input videos, which impedes the generation of complete, all-rounded 3D avatars that can render from any novel views. We introduce an innovative framework, video-to-avatar360, to reconstruct a full 360-degree implicit neural head avatar from a single monocular frontal video. We first propose to use the signed distance function extracted from the prior mesh as a condition to the canonical Neural Radiance Field, to provide a coarse clue for the geometry of the full head avatar. We then incorporate a personalized diffusion guidance, DreamBooth-SDS, to optimize the NeRF in the novel views while being identity-preserving. Video-to-Avatar360 enables the generation of photorealistic 360-degree avatars, achieving a substantial performance leap over the state-of-the-art, for both reference-view reconstruction and novel view synthesis.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">Ongoing Project with Snap and MBZUAI</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tags/aigc/>AIGC</a>
<a class="badge badge-light" href=/tags/3d/>3D</a>
<a class="badge badge-light" href=/tags/avatar/>Avatar</a></div></div></div><script src=/js/mathjax-config.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin=anonymous async></script>
<script>hljs.initHighlightingOnLoad()</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",talk:"Talks"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/academic.min.5c1ab144ecb9ec087e4ea0940632fbec.js></script><div class=container><footer class=site-footer><p class=powered-by>© 2023 Dai-Jie Wu. Thanks for the template from wowchemy-hugo-themes.
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>